{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffab6a0e",
   "metadata": {},
   "source": [
    "## üì¶ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from nlp.embeddings import EmbeddingGenerator\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = os.getenv('GCP_PROJECT_ID', 'sg-job-market')\n",
    "DATASET_ID = os.getenv('BQ_DATASET_ID', 'sg_job_market')\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Dataset: {DATASET_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69faec08",
   "metadata": {},
   "source": [
    "## üìä Load Embeddings from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a654442",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    e.job_id,\n",
    "    e.source,\n",
    "    e.embedding,\n",
    "    e.model_name,\n",
    "    e.created_at,\n",
    "    c.job_title,\n",
    "    c.company_name,\n",
    "    c.job_location,\n",
    "    c.job_classification,\n",
    "    c.job_salary_mid_sgd_monthly\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.job_embeddings` e\n",
    "JOIN `{PROJECT_ID}.{DATASET_ID}.cleaned_jobs` c\n",
    "    ON e.job_id = c.job_id AND e.source = c.source\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "print(\"Loading embeddings from BigQuery...\")\n",
    "df = client.query(query).to_dataframe()\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(df):,} jobs with embeddings\")\n",
    "print(f\"Embedding dimension: {len(df['embedding'].iloc[0])}\")\n",
    "print(f\"\\nSample data:\")\n",
    "df[['job_title', 'company_name', 'job_classification']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848d4c8",
   "metadata": {},
   "source": [
    "## üîç Test Similarity Search\n",
    "\n",
    "Find jobs similar to a query using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ca8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embedding for query\n",
    "generator = EmbeddingGenerator()\n",
    "query_text = \"Senior Data Scientist with Python and machine learning experience\"\n",
    "\n",
    "print(f\"Query: {query_text}\")\n",
    "print(\"\\nGenerating query embedding...\")\n",
    "query_embedding = generator.embed_texts([query_text])[0]\n",
    "\n",
    "print(f\"‚úÖ Query embedding shape: {query_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embeddings_matrix = np.vstack(df['embedding'].values)\n",
    "similarities = cosine_similarity([query_embedding], embeddings_matrix)[0]\n",
    "\n",
    "# Add similarity scores to dataframe\n",
    "df['similarity'] = similarities\n",
    "\n",
    "# Get top 10 similar jobs\n",
    "top_jobs = df.nlargest(10, 'similarity')[[\n",
    "    'job_title', 'company_name', 'job_classification', \n",
    "    'job_location', 'job_salary_mid_sgd_monthly', 'similarity'\n",
    "]]\n",
    "\n",
    "print(f\"\\nüéØ Top 10 Similar Jobs:\\n\")\n",
    "for idx, row in top_jobs.iterrows():\n",
    "    print(f\"{row['similarity']:.3f} | {row['job_title'][:50]:50} | {row['company_name'][:30]:30} | ${row['job_salary_mid_sgd_monthly']:.0f}\")\n",
    "\n",
    "top_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8984f",
   "metadata": {},
   "source": [
    "## üìà Embedding Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a959c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check embedding statistics\n",
    "embeddings_matrix = np.vstack(df['embedding'].values)\n",
    "\n",
    "print(\"üìä Embedding Statistics:\\n\")\n",
    "print(f\"Shape: {embeddings_matrix.shape}\")\n",
    "print(f\"Value range: [{embeddings_matrix.min():.3f}, {embeddings_matrix.max():.3f}]\")\n",
    "print(f\"Mean: {embeddings_matrix.mean():.3f}\")\n",
    "print(f\"Std: {embeddings_matrix.std():.3f}\")\n",
    "\n",
    "# Check normalization (SBERT embeddings should have norm ‚âà 1)\n",
    "norms = np.linalg.norm(embeddings_matrix, axis=1)\n",
    "print(f\"\\nüìè Vector Norms:\")\n",
    "print(f\"Mean: {norms.mean():.3f}\")\n",
    "print(f\"Std: {norms.std():.3f}\")\n",
    "print(f\"Min: {norms.min():.3f}\")\n",
    "print(f\"Max: {norms.max():.3f}\")\n",
    "\n",
    "if abs(norms.mean() - 1.0) < 0.01:\n",
    "    print(\"\\n‚úÖ Embeddings are properly normalized (unit vectors)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Warning: Embeddings may not be normalized\")\n",
    "\n",
    "# Plot norm distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(norms, bins=50, edgecolor='black')\n",
    "plt.axvline(1.0, color='red', linestyle='--', label='Expected norm = 1.0')\n",
    "plt.xlabel('Vector Norm')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Embedding Vector Norms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f74ba",
   "metadata": {},
   "source": [
    "## üé® Visualize Embeddings with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D using PCA\n",
    "print(\"Reducing 384 dimensions to 2D with PCA...\")\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "embeddings_2d = pca.fit_transform(embeddings_matrix)\n",
    "\n",
    "df['pca_1'] = embeddings_2d[:, 0]\n",
    "df['pca_2'] = embeddings_2d[:, 1]\n",
    "\n",
    "print(f\"‚úÖ Explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Plot by job classification\n",
    "plt.figure(figsize=(12, 8))\n",
    "for classification in df['job_classification'].dropna().unique()[:10]:\n",
    "    subset = df[df['job_classification'] == classification]\n",
    "    plt.scatter(subset['pca_1'], subset['pca_2'], \n",
    "                label=classification, alpha=0.6, s=30)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('Job Embeddings Visualization (PCA)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c3f98",
   "metadata": {},
   "source": [
    "## üéØ Analyze Similarity by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a180be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by job classification and check intra-cluster similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_intra_cluster_similarity(df, classification):\n",
    "    \"\"\"Calculate average similarity within a job classification.\"\"\"\n",
    "    subset = df[df['job_classification'] == classification]\n",
    "    if len(subset) < 2:\n",
    "        return np.nan\n",
    "    \n",
    "    embeddings = np.vstack(subset['embedding'].values)\n",
    "    sim_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Get upper triangle (exclude diagonal)\n",
    "    mask = np.triu(np.ones_like(sim_matrix, dtype=bool), k=1)\n",
    "    return sim_matrix[mask].mean()\n",
    "\n",
    "# Calculate for top categories\n",
    "top_categories = df['job_classification'].value_counts().head(10).index\n",
    "similarity_scores = []\n",
    "\n",
    "for cat in top_categories:\n",
    "    score = calculate_intra_cluster_similarity(df, cat)\n",
    "    similarity_scores.append({\n",
    "        'category': cat,\n",
    "        'count': len(df[df['job_classification'] == cat]),\n",
    "        'avg_similarity': score\n",
    "    })\n",
    "\n",
    "sim_df = pd.DataFrame(similarity_scores).sort_values('avg_similarity', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Intra-Category Similarity (Higher = More Cohesive):\\n\")\n",
    "print(sim_df.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sim_df['category'], sim_df['avg_similarity'])\n",
    "plt.xlabel('Average Cosine Similarity')\n",
    "plt.title('Embedding Cohesiveness by Job Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375327f9",
   "metadata": {},
   "source": [
    "## üíæ Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã EMBEDDING PIPELINE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n‚úÖ Total Jobs with Embeddings: {len(df):,}\")\n",
    "print(f\"‚úÖ Embedding Dimension: {len(df['embedding'].iloc[0])}\")\n",
    "print(f\"‚úÖ Model: {df['model_name'].iloc[0]}\")\n",
    "print(f\"‚úÖ Sources: {df['source'].unique().tolist()}\")\n",
    "print(f\"\\nüìä Job Categories: {df['job_classification'].nunique()}\")\n",
    "print(f\"üìä Companies: {df['company_name'].nunique()}\")\n",
    "print(f\"üìä Locations: {df['job_location'].nunique()}\")\n",
    "\n",
    "print(f\"\\nüéØ Quality Metrics:\")\n",
    "print(f\"  Vector norm: {norms.mean():.3f} ¬± {norms.std():.3f} (expected: 1.0)\")\n",
    "print(f\"  Value range: [{embeddings_matrix.min():.3f}, {embeddings_matrix.max():.3f}]\")\n",
    "print(f\"  PCA variance (2D): {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ EMBEDDINGS ARE PRODUCTION-READY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Create vector index: python -m nlp.create_vector_index\")\n",
    "print(\"  2. Train ML models: python -m ml.train\")\n",
    "print(\"  3. Build RAG pipeline: python -m genai.rag\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
